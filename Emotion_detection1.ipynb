{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **TrainEmotionDetector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "IkuMANb8rEER"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Flatten\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import model_from_json\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.metrics import confusion_matrix, classification_report,ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "9W5SpBkPxS9p"
   },
   "outputs": [],
   "source": [
    "# Initialize image data generator with rescaling\n",
    "train_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "validation_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "hRqt-NBQxS6N"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28709 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess all test images\n",
    "train_generator = train_data_gen.flow_from_directory(\n",
    "        'data/train',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "rDMtaUayxS3u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess all train images\n",
    "validation_generator = validation_data_gen.flow_from_directory(\n",
    "        'data/test',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wwMoVCEQxS1H"
   },
   "outputs": [],
   "source": [
    "# create model structure\n",
    "emotion_model = Sequential()\n",
    "\n",
    "emotion_model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(48, 48, 1)))\n",
    "emotion_model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "emotion_model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "emotion_model.add(Dropout(0.25))\n",
    "\n",
    "emotion_model.add(Flatten())\n",
    "emotion_model.add(Dense(1024, activation='relu'))\n",
    "emotion_model.add(Dropout(0.5))\n",
    "emotion_model.add(Dense(7, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "uTnMKcZuxSyY"
   },
   "outputs": [],
   "source": [
    "cv2.ocl.setUseOpenCL(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "GPlXRj5xxSvv"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nada Khaled\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\optimizers\\optimizer_v2\\adam.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "emotion_model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=0.0001, decay=1e-6), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "vAFnYAPTxSs5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nada Khaled\\AppData\\Local\\Temp\\ipykernel_7532\\1401183085.py:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  emotion_model_info = emotion_model.fit_generator(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "448/448 [==============================] - 260s 579ms/step - loss: 1.8018 - accuracy: 0.2598 - val_loss: 1.7240 - val_accuracy: 0.3221\n",
      "Epoch 2/20\n",
      "448/448 [==============================] - 214s 479ms/step - loss: 1.6367 - accuracy: 0.3615 - val_loss: 1.5593 - val_accuracy: 0.4110\n",
      "Epoch 3/20\n",
      "448/448 [==============================] - 91s 204ms/step - loss: 1.5484 - accuracy: 0.4050 - val_loss: 1.4857 - val_accuracy: 0.4351\n",
      "Epoch 4/20\n",
      "448/448 [==============================] - 102s 227ms/step - loss: 1.4839 - accuracy: 0.4291 - val_loss: 1.4464 - val_accuracy: 0.4420\n",
      "Epoch 5/20\n",
      "448/448 [==============================] - 93s 207ms/step - loss: 1.4293 - accuracy: 0.4520 - val_loss: 1.3762 - val_accuracy: 0.4738\n",
      "Epoch 6/20\n",
      "448/448 [==============================] - 92s 206ms/step - loss: 1.3767 - accuracy: 0.4723 - val_loss: 1.3287 - val_accuracy: 0.4950\n",
      "Epoch 7/20\n",
      "448/448 [==============================] - 112s 251ms/step - loss: 1.3266 - accuracy: 0.4952 - val_loss: 1.3082 - val_accuracy: 0.5102\n",
      "Epoch 8/20\n",
      "448/448 [==============================] - 122s 272ms/step - loss: 1.2807 - accuracy: 0.5144 - val_loss: 1.2544 - val_accuracy: 0.5190\n",
      "Epoch 9/20\n",
      "448/448 [==============================] - 122s 273ms/step - loss: 1.2461 - accuracy: 0.5307 - val_loss: 1.2316 - val_accuracy: 0.5308\n",
      "Epoch 10/20\n",
      "448/448 [==============================] - 123s 274ms/step - loss: 1.2122 - accuracy: 0.5439 - val_loss: 1.2222 - val_accuracy: 0.5328\n",
      "Epoch 11/20\n",
      "448/448 [==============================] - 126s 281ms/step - loss: 1.1833 - accuracy: 0.5562 - val_loss: 1.1798 - val_accuracy: 0.5530\n",
      "Epoch 12/20\n",
      "448/448 [==============================] - 129s 288ms/step - loss: 1.1608 - accuracy: 0.5654 - val_loss: 1.1706 - val_accuracy: 0.5568\n",
      "Epoch 13/20\n",
      "448/448 [==============================] - 132s 294ms/step - loss: 1.1259 - accuracy: 0.5777 - val_loss: 1.1517 - val_accuracy: 0.5667\n",
      "Epoch 14/20\n",
      "448/448 [==============================] - 126s 281ms/step - loss: 1.1035 - accuracy: 0.5865 - val_loss: 1.1359 - val_accuracy: 0.5728\n",
      "Epoch 15/20\n",
      "448/448 [==============================] - 191s 426ms/step - loss: 1.0831 - accuracy: 0.5931 - val_loss: 1.1291 - val_accuracy: 0.5759\n",
      "Epoch 16/20\n",
      "448/448 [==============================] - 114s 255ms/step - loss: 1.0611 - accuracy: 0.6044 - val_loss: 1.1185 - val_accuracy: 0.5798\n",
      "Epoch 17/20\n",
      "448/448 [==============================] - 168s 376ms/step - loss: 1.0398 - accuracy: 0.6138 - val_loss: 1.1117 - val_accuracy: 0.5780\n",
      "Epoch 18/20\n",
      "448/448 [==============================] - 117s 262ms/step - loss: 1.0171 - accuracy: 0.6195 - val_loss: 1.1086 - val_accuracy: 0.5816\n",
      "Epoch 19/20\n",
      "448/448 [==============================] - 89s 198ms/step - loss: 0.9963 - accuracy: 0.6308 - val_loss: 1.1029 - val_accuracy: 0.5841\n",
      "Epoch 20/20\n",
      "448/448 [==============================] - 201s 449ms/step - loss: 0.9734 - accuracy: 0.6377 - val_loss: 1.0945 - val_accuracy: 0.5886\n"
     ]
    }
   ],
   "source": [
    "# Train the neural network/model\n",
    "emotion_model_info = emotion_model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=28709 // 64,\n",
    "        epochs=20,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=7178 // 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit Model \n",
    "with tf.device('/GPU:0'):\n",
    "   results = emotion_model.fit(train_generator,epochs=20, validation_data=validation_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history from 20 epochs that were ran by a model (loss, accuracy, validation loss, validation accuracy)\n",
    "results.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we get the dictionary 'history'\n",
    "results.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax=plt.subplots(1,2,figsize=(10,5))\n",
    "\n",
    "ax[0].plot(results.history['loss'],label='training')\n",
    "ax[0].plot(results.history['val_loss'],label='validation')\n",
    "ax[0].legend()\n",
    "ax[0].set_title('Loss with epochs')\n",
    "\n",
    "ax[1].plot(results.history['accuracy'],label='training')\n",
    "ax[1].plot(results.history['val_accuracy'],label='validation')\n",
    "ax[1].legend()\n",
    "ax[1].set_title('Accuracy with epochs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M8xsUs0axSqD"
   },
   "outputs": [],
   "source": [
    "# save model structure in jason file\n",
    "model_json = emotion_model.to_json()\n",
    "with open(\"emotion_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VCU7oT06xSnh"
   },
   "outputs": [],
   "source": [
    "# save trained model weight in .h5 file\n",
    "emotion_model.save_weights('emotion_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "h-odET70xr25"
   },
   "source": [
    "# **TestEmotionDetector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zyJTcxxcxShg"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "scTfcFWOxScJ"
   },
   "outputs": [],
   "source": [
    "emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5sLVYlmBxSZ5"
   },
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('model/emotion_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "emotion_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bAwSH9QexSXk"
   },
   "outputs": [],
   "source": [
    "# load weights into new model\n",
    "emotion_model.load_weights(\"model/emotion_model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NJUDJtkxSVB"
   },
   "outputs": [],
   "source": [
    "# start the webcam feed\n",
    "#cap = cv2.VideoCapture(0)\n",
    "\n",
    "# pass here your video path\n",
    "cap = cv2.VideoCapture(\"video.mp4\")\n",
    "\n",
    "\n",
    "while True:\n",
    "    # Find haar cascade to draw bounding box around face\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, (1280, 720))\n",
    "    if not ret:\n",
    "        break\n",
    "    face_detector = cv2.CascadeClassifier('haarcascades/haarcascade_frontalface_default.xml')\n",
    "    gray_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # detect faces available on camera\n",
    "    num_faces = face_detector.detectMultiScale(gray_frame, scaleFactor=1.3, minNeighbors=5)\n",
    "\n",
    "    # take each face available on the camera and Preprocess it\n",
    "    for (x, y, w, h) in num_faces:\n",
    "        cv2.rectangle(frame, (x, y-50), (x+w, y+h+10), (0, 255, 0), 4)\n",
    "        roi_gray_frame = gray_frame[y:y + h, x:x + w]\n",
    "        cropped_img = np.expand_dims(np.expand_dims(cv2.resize(roi_gray_frame, (48, 48)), -1), 0)\n",
    "\n",
    "        # predict the emotions\n",
    "        emotion_prediction = emotion_model.predict(cropped_img)\n",
    "        maxindex = int(np.argmax(emotion_prediction))\n",
    "        cv2.putText(frame, emotion_dict[maxindex], (x+5, y-20), cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('Emotion Detection', frame)\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JlUfKo07ytpq"
   },
   "source": [
    "# **EvaluateEmotionDetector**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qVTEm-INxSP_"
   },
   "outputs": [],
   "source": [
    "emotion_dict = {0: \"Angry\", 1: \"Disgusted\", 2: \"Fearful\", 3: \"Happy\", 4: \"Neutral\", 5: \"Sad\", 6: \"Surprised\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "i6MpayMmywcY"
   },
   "outputs": [],
   "source": [
    "# load json and create model\n",
    "json_file = open('model/emotion_model.json', 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "emotion_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qffFDjXIywY6"
   },
   "outputs": [],
   "source": [
    "# load weights into new model\n",
    "emotion_model.load_weights(\"model/emotion_model.h5\")\n",
    "print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gp4Aw1Q1ywU0"
   },
   "outputs": [],
   "source": [
    "# Initialize image data generator with rescaling\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LgO_Gc8nywSJ"
   },
   "outputs": [],
   "source": [
    "# Preprocess all test images\n",
    "test_generator = test_data_gen.flow_from_directory(\n",
    "        'data/test',\n",
    "        target_size=(48, 48),\n",
    "        batch_size=64,\n",
    "        color_mode=\"grayscale\",\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IjmvHdcHywPu"
   },
   "outputs": [],
   "source": [
    "# do prediction on test data\n",
    "predictions = emotion_model.predict_generator(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VBzK3RilywNK"
   },
   "outputs": [],
   "source": [
    "# see predictions\n",
    "# for result in predictions:\n",
    "#     max_index = int(np.argmax(result))\n",
    "#     print(emotion_dict[max_index])\n",
    "\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "# confusion matrix\n",
    "c_matrix = confusion_matrix(test_generator.classes, predictions.argmax(axis=1))\n",
    "print(c_matrix)\n",
    "cm_display = ConfusionMatrixDisplay(confusion_matrix=c_matrix, display_labels=emotion_dict)\n",
    "cm_display.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jv6nyGmnywKj"
   },
   "outputs": [],
   "source": [
    "# Classification report\n",
    "print(\"-----------------------------------------------------------------\")\n",
    "print(classification_report(test_generator.classes, predictions.argmax(axis=1)))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
